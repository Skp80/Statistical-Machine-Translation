{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "SMT_English_to_Hindi.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayarghoshroy/Statistical-Machine-Translation/blob/master/SMT_English_to_Hindi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7y4if32xY-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Statistical Machine Translation System\n",
        "# English to Hindi\n",
        "\n",
        "# IBM Model 1 for Word Translation Task\n",
        "# Word Alignment based on Relative Positions\n",
        "# Bigram Language Modelling with Laplace Smoothing and Backoff"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cVVv4e0VoF0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gWKU42vygZn",
        "colab_type": "code",
        "outputId": "f1c57c29-8210-48a8-b872-757dfca3171e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKVfJuwSxY-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized_stores = {'en_train': [], 'en_dev': [], 'en_test': [], 'hi_train': [], 'hi_dev': [], 'hi_test': []}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OCBe2XixY--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load data files into your Google Drive in a directory named \"NLP_Translation\"\n",
        "# Alternatively, provide location to the folder 'data_file'\n",
        "\n",
        "for key in tokenized_stores:\n",
        "    file_name = \"/content/drive/My Drive/NLP_Translation/\" + str(key)[3:] + \".\" + str(key)[0:2]\n",
        "    load = open(file_name)\n",
        "    sentences = load.read().split('\\n')\n",
        "    \n",
        "    for sentence in sentences:\n",
        "        token_store = sentence.split(' ')\n",
        "        tokenized_stores[key].append(token_store)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SWltGqbxY_H",
        "colab_type": "code",
        "outputId": "c3cb1858-1c97-401c-e57b-a6336a76b17f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(tokenized_stores['hi_train'][2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ऑपरेशन', 'के', 'दौरान', 'लैन्स', 'प्रत्यारोपण', 'आँख', 'के', 'अगले', 'भाग', ',', 'आइरिस', 'के', 'आगे', 'किया', 'जाता', 'है', '।']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIZNBPNAxY_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_size = len(tokenized_stores['en_train'])\n",
        "dev_size = len(tokenized_stores['en_dev'])\n",
        "test_size = len(tokenized_stores['en_test'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VMMiv4BxY_c",
        "colab_type": "code",
        "outputId": "1942c9f9-68d0-454e-aee8-b950025be200",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# making the vocabulary\n",
        "\n",
        "en_words = {}\n",
        "hi_words = {}\n",
        "\n",
        "for key in tokenized_stores:\n",
        "    if str(key)[0] == 'e':\n",
        "        # creating en_words\n",
        "        for sentence in tokenized_stores[key]:\n",
        "            for word in sentence:\n",
        "                if word in en_words:\n",
        "                    en_words[word] += 1\n",
        "                else:\n",
        "                    en_words[word] = 1\n",
        "    else:\n",
        "        # creating hi_words\n",
        "        for sentence in tokenized_stores[key]:\n",
        "            for word in sentence:\n",
        "                if word in hi_words:\n",
        "                    hi_words[word] += 1\n",
        "                else:\n",
        "                    hi_words[word] = 1\n",
        "                    \n",
        "en_vocab = len(en_words)\n",
        "hi_vocab = len(hi_words)\n",
        "print(\"Number of Unique Words:\")\n",
        "print(\"> English:\", str(en_vocab))\n",
        "print(\"> Hindi:\", str(hi_vocab))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Unique Words:\n",
            "> English: 36879\n",
            "> Hindi: 43921\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCA1636BxY_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating the 't'\n",
        "t = {}\n",
        "# usage: t[('EN_word', 'HI_word')] = probability of EN_Word given HI_word\n",
        "uniform = 1 / (en_vocab * hi_vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKUGRo00xY_p",
        "colab_type": "code",
        "outputId": "460b01c5-733a-4542-f812-0c3143a31ef4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "source": [
        "n_iters = 0\n",
        "max_iters = 25\n",
        "\n",
        "fine_tune = 1\n",
        "has_converged = False\n",
        "\n",
        "while n_iters < max_iters and has_converged == False:\n",
        "    has_converged = True\n",
        "    max_change = -1\n",
        "\n",
        "    n_iters += 1\n",
        "    count = {}\n",
        "    total = {}\n",
        "    for index in range(train_size):\n",
        "        s_total = {}\n",
        "        for en_word in tokenized_stores['en_train'][index]:\n",
        "            s_total[en_word] = 0\n",
        "            for hi_word in tokenized_stores['hi_train'][index]:\n",
        "                if (en_word, hi_word) not in t:\n",
        "                    t[(en_word, hi_word)] = uniform\n",
        "                s_total[en_word] += t[(en_word, hi_word)]\n",
        "\n",
        "        for en_word in tokenized_stores['en_train'][index]:\n",
        "            for hi_word in tokenized_stores['hi_train'][index]:\n",
        "                if (en_word, hi_word) not in count:\n",
        "                    count[(en_word, hi_word)] = 0\n",
        "                count[(en_word, hi_word)] += (t[(en_word, hi_word)] / s_total[en_word])\n",
        "\n",
        "                if hi_word not in total:\n",
        "                    total[hi_word] = 0\n",
        "                total[hi_word] += (t[(en_word, hi_word)] / s_total[en_word])\n",
        "\n",
        "    # estimating the probabilities\n",
        "\n",
        "    if fine_tune == 0:\n",
        "      updated = {}\n",
        "      # train for all valid word pairs s.t count(en_word, hi_word) > 0\n",
        "      for index in range(train_size):\n",
        "          for hi_word in tokenized_stores['hi_train'][index]:\n",
        "              for en_word in tokenized_stores['en_train'][index]:\n",
        "                  if (en_word, hi_word) in updated:\n",
        "                      continue\n",
        "                  updated[(en_word, hi_word)] = 1\n",
        "                  if abs(t[(en_word, hi_word)] - count[(en_word, hi_word)] / total[hi_word]) > 0.01:\n",
        "                      has_converged = False\n",
        "                      max_change = max(max_change, abs(t[(en_word, hi_word)] - count[(en_word, hi_word)] / total[hi_word]))\n",
        "                  t[(en_word, hi_word)] = count[(en_word, hi_word)] / total[hi_word]\n",
        "\n",
        "    elif fine_tune == 1:\n",
        "      # train it only for 1000 most frequent words in English and Hindi\n",
        "      max_words = 1000\n",
        "      n_hi_words = 0\n",
        "      updates = 0\n",
        "\n",
        "      for hi_word_tuples in sorted(hi_words.items(), key = lambda k:(k[1], k[0]), reverse = True):\n",
        "          hi_word = hi_word_tuples[0]\n",
        "          n_hi_words += 1\n",
        "          if n_hi_words > max_words:\n",
        "              break\n",
        "          n_en_words = 0\n",
        "          for en_word_tuples in sorted(en_words.items(), key = lambda k:(k[1], k[0]), reverse = True):\n",
        "              en_word = en_word_tuples[0]\n",
        "              n_en_words += 1\n",
        "              if n_en_words > max_words:\n",
        "                  break\n",
        "              if (en_word, hi_word) not in count or hi_word not in total:\n",
        "                  continue\n",
        "                  # assume in this case: t[(en_word, hi_word)] = uniform\n",
        "              else:\n",
        "                  if abs(t[(en_word, hi_word)] - count[(en_word, hi_word)] / total[hi_word]) > 0.005:\n",
        "                      has_converged = False\n",
        "                      max_change = max(max_change, abs(t[(en_word, hi_word)] - count[(en_word, hi_word)] / total[hi_word]))\n",
        "                  t[(en_word, hi_word)] = count[(en_word, hi_word)] / total[hi_word]\n",
        "\n",
        "    print(\"Iteration \" + str(n_iters) + \" Completed, Maximum Change: \" + str(max_change))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1 Completed, Maximum Change: 0.12702983945877983\n",
            "Iteration 2 Completed, Maximum Change: 0.37839562630629314\n",
            "Iteration 3 Completed, Maximum Change: 0.217407035860872\n",
            "Iteration 4 Completed, Maximum Change: 0.13005997455980178\n",
            "Iteration 5 Completed, Maximum Change: 0.08057651269471866\n",
            "Iteration 6 Completed, Maximum Change: 0.04856997020110787\n",
            "Iteration 7 Completed, Maximum Change: 0.03555362770400777\n",
            "Iteration 8 Completed, Maximum Change: 0.029406614861381575\n",
            "Iteration 9 Completed, Maximum Change: 0.02457095418019195\n",
            "Iteration 10 Completed, Maximum Change: 0.020788408537065484\n",
            "Iteration 11 Completed, Maximum Change: 0.018719192726659395\n",
            "Iteration 12 Completed, Maximum Change: 0.01647236630228205\n",
            "Iteration 13 Completed, Maximum Change: 0.014208922903773125\n",
            "Iteration 14 Completed, Maximum Change: 0.012183247164818\n",
            "Iteration 15 Completed, Maximum Change: 0.01070533230776105\n",
            "Iteration 16 Completed, Maximum Change: 0.009634828804602424\n",
            "Iteration 17 Completed, Maximum Change: 0.008727420374992523\n",
            "Iteration 18 Completed, Maximum Change: 0.00794696548613838\n",
            "Iteration 19 Completed, Maximum Change: 0.007265622693145457\n",
            "Iteration 20 Completed, Maximum Change: 0.006662515701654326\n",
            "Iteration 21 Completed, Maximum Change: 0.006122542417748678\n",
            "Iteration 22 Completed, Maximum Change: 0.005635058267058124\n",
            "Iteration 23 Completed, Maximum Change: 0.005192580334827057\n",
            "Iteration 24 Completed, Maximum Change: -1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yaalpW64cA-",
        "colab_type": "code",
        "outputId": "9300bc6c-6cfe-4553-eec3-c916d138a008",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "source": [
        "# displaying the most confident translation pairs\n",
        "limit = 40\n",
        "for element in sorted(t.items(), key = lambda k:(k[1], k[0]), reverse = True):\n",
        "  print(element)\n",
        "  limit -= 1\n",
        "  if limit <= 0:\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(('repeated', 'दुसरे'), 1.0)\n",
            "(('remove', '0.1'), 1.0)\n",
            "(('Shah', 'शाह'), 1.0)\n",
            "(('Delhi', 'दिल्ली'), 1.0)\n",
            "(('.', 'रौहें'), 1.0)\n",
            "(('', ''), 1.0)\n",
            "(('and', 'एवं'), 0.9999999999999996)\n",
            "(('and', 'व'), 0.9999999999999954)\n",
            "(('and', 'और'), 0.9999999999999625)\n",
            "(('or', 'या'), 0.9999999999998754)\n",
            "(('skin', 'त्वचा'), 0.9999999999998568)\n",
            "(('mood', 'मूड'), 0.9999999999997584)\n",
            "(('with', 'विद'), 0.9999999999996376)\n",
            "(('and', 'तथा'), 0.9999999999994506)\n",
            "(('Ahead', 'विरही'), 0.9999999999982141)\n",
            "(('Ahead', 'ढोंकों'), 0.9999999999982141)\n",
            "((',', 'chakra'), 0.9999999999816634)\n",
            "(('Kalimpong', 'कालिमपौंग'), 0.9999999999552232)\n",
            "(('Sultan', 'सुल्तान'), 0.9999999999434265)\n",
            "(('list', 'लिस्ट'), 0.9999999998675534)\n",
            "(('Manali', 'मनाली'), 0.9999999997186086)\n",
            "(('20', '20'), 0.9999999995469487)\n",
            "(('oil', 'तेल'), 0.9999999995355847)\n",
            "(('sandwich', 'सैंडविच'), 0.9999999932738886)\n",
            "(('water', 'पानी'), 0.9999999921623545)\n",
            "(('Chloral', 'क्लोरल'), 0.999999990685679)\n",
            "((',', ','), 0.999999970652084)\n",
            "((',', 'सीकर'), 0.9999999083719832)\n",
            "(('chest', 'छाती'), 0.9999998557910521)\n",
            "(('Jong', 'जौंग'), 0.9999997886305345)\n",
            "(('...', 'सुहागे'), 0.9999996348863522)\n",
            "(('Mansar', 'मंसर'), 0.9999993736201414)\n",
            "(('like', 'जैसी'), 0.9999980404696431)\n",
            "(('which', 'जोकि'), 0.9999973511846354)\n",
            "(('Aurangzeb', 'औरंगजेब'), 0.9999962750185045)\n",
            "(('tourists', 'पर्यटकों'), 0.9999947012589606)\n",
            "(('milk', 'दूध'), 0.999993066958165)\n",
            "(('beautiful', 'खूबसूरत'), 0.9999821568573053)\n",
            "(('Balaji', 'बालाजी'), 0.9999729130467053)\n",
            "(('.', 'एन.सी.'), 0.9999667123517988)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpMllrHFDYV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving the translation model\n",
        "file = open(\"translation_model\",\"wb\")\n",
        "pickle.dump(t,file)\n",
        "file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wQ0a-EARrIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using the model trained until convergence\n",
        "# use link to the saved model\n",
        "pickle_in = open(\"/content/drive/My Drive/NLP_Translation/IBM_model_1_translation_128_iters.pkl\",\"rb\")\n",
        "t = pickle.load(pickle_in)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yaz1CgJoCllZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "I = {}\n",
        "for index in range(train_size):\n",
        "    for en_id in range(len(tokenized_stores['en_train'][index])):\n",
        "        length = len(tokenized_stores['en_train'][index])\n",
        "        if length not in I:\n",
        "            I[length] = {} # maps the positional difference to a tuple: (sum of t's, count)\n",
        "        for hi_id in range(len(tokenized_stores['hi_train'][index])):\n",
        "            if (hi_id - en_id) not in I[length]:\n",
        "                I[length][(hi_id - en_id)] = [t[(tokenized_stores['en_train'][index][en_id], tokenized_stores['hi_train'][index][hi_id])], 1]\n",
        "            else:\n",
        "                I[length][(hi_id - en_id)][0] += t[(tokenized_stores['en_train'][index][en_id], tokenized_stores['hi_train'][index][hi_id])]\n",
        "                I[length][(hi_id - en_id)][1] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wh6ogFdO2r_-",
        "colab_type": "code",
        "outputId": "f29cf8b2-3f9e-4980-d8df-6fff70839ae6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# viewing the available sentence lengths encountered during training\n",
        "sentence_lengths = []\n",
        "for key in I.keys():\n",
        "    if key not in sentence_lengths:\n",
        "        sentence_lengths.append(key)\n",
        "sentence_lengths.sort()\n",
        "print(sentence_lengths)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 79, 80, 83, 93, 96, 100, 107]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CNo6HGz6lqK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# computing the alignment probabilities\n",
        "# p[I][hi_id - en_id] = p(i | i', I)\n",
        "\n",
        "p = {}\n",
        "for key in I.keys():\n",
        "    p[key] = {}\n",
        "    sum_val = 0\n",
        "    for diff in I[key].keys():\n",
        "        p[key][diff] = I[key][diff][0] / I[key][diff][1]\n",
        "        sum_val += p[key][diff]\n",
        "    for diff in p[key].keys():\n",
        "        p[key][diff] /= sum_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5s0yqic8zCn",
        "colab_type": "code",
        "outputId": "8f33c452-3a70-4527-8dbf-72f22457eca0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(p[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 0.05908559983928417, 1: 0.075548583467321, 2: 0.025267026464583134, 3: 0.04443576862022724, 4: 0.020455693337409517, 5: 0.07354916495589295, 6: 0.03119631296244615, 7: 0.00014539181336456066, 8: 0.015414522361945508, 9: 0.1961314091328629, 10: 2.502886985142569e-15, 11: 0.03552186572394681, 12: 1.843188072165254e-11, 13: 9.753171479827872e-22, 14: 2.3439144289883087e-06, 15: 0.04722688600592951, 16: 1.1444222502531302e-23, 17: 0.08182277286067562, 18: 0.2941966585212477}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWI7HCoI81Qa",
        "colab_type": "code",
        "outputId": "34a65ba8-e85c-4ef2-e6f4-bab50272ad72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "for index in range(train_size):\n",
        "    length_en = len(tokenized_stores['en_train'][index])\n",
        "    length_hi = len(tokenized_stores['hi_train'][index])\n",
        "    if length_hi - length_en > 10 and length_en == 1:\n",
        "        print(\"Length of English Sentence:\", str(length_en))\n",
        "        print(\"Length of Hindi Sentence:\", str(length_hi))\n",
        "# there exists an English sentence with one token s.t the Hindi translation contains 19 tokens"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of English Sentence: 1\n",
            "Length of Hindi Sentence: 19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqzyU-2g9_jk",
        "colab_type": "code",
        "outputId": "df7b5ff2-61ef-4016-f951-2f3049659ada",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# computing initial transitions\n",
        "init = {}\n",
        "for length in p:\n",
        "    max_prob = -1\n",
        "    max_jump = 0\n",
        "    for key in p[length].keys():\n",
        "        if p[length][key] > max_prob:\n",
        "            max_prob = p[length][key]\n",
        "            max_jump = key\n",
        "    init[length] = max_jump\n",
        "\n",
        "print(init)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{10: 0, 23: -1, 18: 0, 33: -1, 8: 44, 19: 0, 31: 42, 25: 0, 13: 0, 20: 49, 15: 0, 9: 0, 7: 0, 5: 38, 12: 43, 24: 46, 21: 0, 29: 0, 6: 0, 22: 45, 11: 47, 17: 0, 46: 49, 16: 0, 26: 56, 36: 0, 4: 25, 14: 0, 27: 0, 32: 0, 42: -2, 39: 0, 30: 0, 38: -1, 34: 0, 3: 72, 28: 0, 48: 54, 41: -3, 60: 60, 45: -1, 37: 0, 43: -1, 40: -1, 35: 0, 47: -4, 49: 1, 57: -1, 2: 20, 69: 67, 44: -1, 100: 0, 54: 0, 52: 62, 53: -2, 58: -2, 66: 73, 51: -2, 50: -5, 59: -3, 68: 66, 56: -3, 55: -2, 71: 6, 96: -6, 62: -2, 70: 0, 74: -5, 73: 1, 63: -1, 72: 0, 80: 66, 65: 64, 75: -73, 1: 18, 83: -1, 107: -105, 67: -2, 64: -2, 93: -4, 79: -77, 61: -56}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12MsJzVKnIcb",
        "colab_type": "code",
        "outputId": "073600df-320f-4477-8b1a-fca8bb0fce10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlM2-MzmExbc",
        "colab_type": "code",
        "outputId": "3b292122-370a-43be-828c-4ec6df1d6e16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# computing the transition probabilities for Hindi\n",
        "bigrams = {}\n",
        "unigrams = {}\n",
        "\n",
        "# training on the train_set\n",
        "def model(dataset_size, dataset_name):\n",
        "    global bigrams\n",
        "    global unigrams\n",
        "    for index in range(dataset_size):\n",
        "        token_A = ''\n",
        "        for hi_token in tokenized_stores[dataset_name][index]:\n",
        "            if hi_token not in unigrams:\n",
        "                unigrams[hi_token] = 1\n",
        "            else:\n",
        "                unigrams[hi_token] += 1\n",
        "            \n",
        "            token_B = hi_token\n",
        "            if (token_A, token_B) not in bigrams:\n",
        "                bigrams[(token_A, token_B)] = 1\n",
        "            else:\n",
        "                bigrams[(token_A, token_B)] += 1\n",
        "            token_A = token_B\n",
        "\n",
        "model(train_size, 'hi_train')\n",
        "model(dev_size, 'hi_dev')\n",
        "\n",
        "bigram_count = len(bigrams)\n",
        "unigram_count = len(unigrams)\n",
        "print(\"Number of Unique Bigrams:\", bigram_count)\n",
        "print(\"Number of Unique Unigrams:\", unigram_count)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Unique Bigrams: 317170\n",
            "Number of Unique Unigrams: 43851\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AF98ePawMnaE",
        "colab_type": "code",
        "outputId": "372dca12-83ff-48cb-c5ee-0142595245c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from itertools import permutations\n",
        "import nltk\n",
        "\n",
        "computed_sentences = []\n",
        "total_BLEU = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 7: 0}\n",
        "null_BLEU_count = 0\n",
        "\n",
        "sorted_t = sorted(t.items(), key = lambda k:(k[1], k[0]), reverse = True)\n",
        "\n",
        "def find_translation(en_token):\n",
        "    for element in sorted_t:\n",
        "        if element[0][0].lower() == en_token:\n",
        "            return element[0][1]\n",
        "    return \"\"\n",
        "\n",
        "def get_prob(seq):\n",
        "    # bigram language model with laplace smoothing and backoff\n",
        "    if len(seq) < 2:\n",
        "        return 1\n",
        "    score = 0\n",
        "    token_A = ''\n",
        "    for hi_token in seq:\n",
        "        token_B = hi_token\n",
        "        if (token_A, token_B) not in bigrams:\n",
        "            if token_B not in unigrams:\n",
        "                continue\n",
        "            else:\n",
        "                score += unigrams[token_B] / unigram_count\n",
        "        else:\n",
        "            score += (bigrams[(token_A, token_B)] + 1)/ (unigrams[token_A] + unigram_count)\n",
        "        token_A = token_B\n",
        "    return score\n",
        "\n",
        "count = 0\n",
        "for index in range(test_size):\n",
        "    if len(tokenized_stores['en_test'][index]) > 8 or len(tokenized_stores['en_test'][index]) < 2:\n",
        "        continue\n",
        "\n",
        "    translated_words = []\n",
        "    for en_token in tokenized_stores['en_test'][index]:\n",
        "        translation = find_translation(en_token)\n",
        "        if translation != \"\":\n",
        "            translated_words.append(translation)\n",
        "\n",
        "    perm = permutations(translated_words)\n",
        "\n",
        "    best_seq = translated_words\n",
        "    best_prob = -1\n",
        "\n",
        "    for seq in perm:\n",
        "        prob = get_prob(seq)\n",
        "        if prob > best_prob:\n",
        "            best_prob = prob\n",
        "            best_seq = seq\n",
        "\n",
        "    BLEU_scores = []\n",
        "    # Collecting BLEU_scores with various kinds of Smoothing\n",
        "    BLEU_scores.append(nltk.translate.bleu_score.sentence_bleu([tokenized_stores['hi_test'][index]], best_seq, smoothing_function=nltk.translate.bleu_score.SmoothingFunction().method1))\n",
        "    BLEU_scores.append(nltk.translate.bleu_score.sentence_bleu([tokenized_stores['hi_test'][index]], best_seq, smoothing_function=nltk.translate.bleu_score.SmoothingFunction().method2))\n",
        "    BLEU_scores.append(nltk.translate.bleu_score.sentence_bleu([tokenized_stores['hi_test'][index]], best_seq, smoothing_function=nltk.translate.bleu_score.SmoothingFunction().method3))\n",
        "    BLEU_scores.append(nltk.translate.bleu_score.sentence_bleu([tokenized_stores['hi_test'][index]], best_seq, smoothing_function=nltk.translate.bleu_score.SmoothingFunction().method4))\n",
        "    BLEU_scores.append(nltk.translate.bleu_score.sentence_bleu([tokenized_stores['hi_test'][index]], best_seq, smoothing_function=nltk.translate.bleu_score.SmoothingFunction().method5))\n",
        "    BLEU_scores.append(nltk.translate.bleu_score.sentence_bleu([tokenized_stores['hi_test'][index]], best_seq, smoothing_function=nltk.translate.bleu_score.SmoothingFunction().method7))\n",
        "\n",
        "    for key in total_BLEU.keys():\n",
        "        if key == 7:\n",
        "            consider = 5\n",
        "        else: consider = key - 1\n",
        "        total_BLEU[key] += BLEU_scores[consider]\n",
        "    \n",
        "    if BLEU_scores[0] == 0:\n",
        "        null_BLEU_count += 1\n",
        "    \n",
        "    count += 1\n",
        "    print(\"Sentence Index: \", str(count))\n",
        "    print(\"English Sentence:\", str(tokenized_stores['en_test'][index]))\n",
        "    print(\"Reference Hindi Sentence:\", str(tokenized_stores['hi_test'][index]))\n",
        "    print(\"Translated Sentence:\", str(best_seq))\n",
        "    print(\"Translation BLEU Scores\", str(BLEU_scores))\n",
        "    \n",
        "    computed_sentences.append([tokenized_stores['en_test'][index], tokenized_stores['hi_test'][index], best_seq, BLEU_scores])\n",
        "\n",
        "tested = count"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence Index:  1\n",
            "English Sentence: ['Your', 'self-confidence', 'also', 'increases', 'with', 'teeth', '.']\n",
            "Reference Hindi Sentence: ['दाँतों', 'से', 'आपका', 'आत्मविश्\\u200dवास', 'भी', 'बढ़ता', 'है', '।']\n",
            "Translated Sentence: ('भी', 'मनोबल', 'बढ़ाती', 'विद', 'दाँतों', 'रौहें')\n",
            "Translation BLEU Scores [0.03478700554542394, 0.1751643270174889, 0.06916271812933181, 0.1700210851830615, 0.0766091750078838, 0.21752950302192342]\n",
            "Sentence Index:  2\n",
            "English Sentence: ['Bacteria', 'stay', 'between', 'our', 'gums', 'and', 'teeth', '.']\n",
            "Reference Hindi Sentence: ['हमारे', 'मसूढ़ों', 'और', 'दाँतों', 'के', 'बीच', 'बैक्टीरिया', 'मौजूद', 'होते', 'हैं', '।']\n",
            "Translated Sentence: ('ठहरते', 'बीच', 'हमारी', 'एवं', 'रौहें', 'मसूड़ों', 'दाँतों')\n",
            "Translation BLEU Scores [0.022182955195367136, 0.11608730201515954, 0.04410363736106613, 0.13373412948094648, 0.0569276469417752, 0.1718622553331596]\n",
            "Sentence Index:  3\n",
            "English Sentence: ['They', 'make', 'teeth', 'dirty', 'and', 'breath', 'stinky', '.']\n",
            "Reference Hindi Sentence: ['ये', 'दाँतों', 'को', 'गंदा', 'और', 'साँसों', 'को', 'बदबूदार', 'बना', 'देते', 'हैं', '।']\n",
            "Translated Sentence: ('बनाते', 'दाँतों', 'गंदे', 'दुर्गन्ध', 'पीपदार', 'रौहें', 'एवं')\n",
            "Translation BLEU Scores [0.016170365420297903, 0.0909326471926252, 0.03214954573057458, 0.09748609794442446, 0.04037671556067758, 0.13741190652760946]\n",
            "Sentence Index:  4\n",
            "English Sentence: ['Clean', 'your', 'teeth', 'properly', '.']\n",
            "Reference Hindi Sentence: ['दाँतों', 'को', 'ठीक', 'से', 'साफ', 'करें', '।']\n",
            "Translated Sentence: ('फेट', 'आपकी', 'दाँतों', 'रौहें')\n",
            "Translation BLEU Scores [0.037951271263104894, 0.1697232447536737, 0.07545383788761363, 0.09241478327137823, 0.04545349273020006, 0.12520207120947965]\n",
            "Sentence Index:  5\n",
            "English Sentence: ['Drink', 'plenty', 'of', 'water', '.']\n",
            "Reference Hindi Sentence: ['खूब', 'पानी', 'पीएँ', '।']\n",
            "Translated Sentence: ('धूल-धक्कड़', 'ऑफ', 'पानी', 'रौहें')\n",
            "Translation BLEU Scores [0.08034284189446518, 0.35930411196308426, 0.15973577606156814, 0.19564209772076444, 0.09622504486493762, 0.2650527868304097]\n",
            "Sentence Index:  6\n",
            "English Sentence: ['With', 'this', 'stink', 'comes', 'from', 'breath', '.']\n",
            "Reference Hindi Sentence: ['इससे', 'साँसों', 'से', 'बदबू', 'आने', 'लगती', 'है', '।']\n",
            "Translated Sentence: ('दुर्गंध', 'उद्\\u200dगमित', 'इस', 'आता', 'दुर्गन्ध', 'रौहें')\n",
            "Translation BLEU Scores [0, 0, 0, 0, 0, 0]\n",
            "Sentence Index:  7\n",
            "English Sentence: ['Chew', 'the', 'sugar-free', 'chewing', 'gum', '.']\n",
            "Reference Hindi Sentence: ['चबाएँ', 'शुगर', 'रहित', 'चुइंग', 'गम', '।']\n",
            "Translated Sentence: ('सेठों', 'बबल', 'गम', 'चबाने', 'रौहें')\n",
            "Translation BLEU Scores [0.0439891724758422, 0.22352339099197038, 0.08745825313180632, 0.16275722768907425, 0.07353024321741747, 0.22219664527356253]\n",
            "Sentence Index:  8\n",
            "English Sentence: ['Get', 'the', 'teeth', 'checked-up', 'regularly', '.']\n",
            "Reference Hindi Sentence: ['नियमित', 'रूप', 'से', 'कराएँ', 'दाँतों', 'की', 'जाँच', '।']\n",
            "Translated Sentence: ('सेठों', 'कैप्सूल्स', 'रौहें', 'दाँतों')\n",
            "Translation BLEU Scores [0.029556479778261396, 0.13218059591958078, 0.05876350803261634, 0.07197270557912354, 0.035399215731610215, 0.09750747110010456]\n",
            "Sentence Index:  9\n",
            "English Sentence: ['Clean', 'the', 'mouth', 'after', 'meal', '.']\n",
            "Reference Hindi Sentence: ['खाने', 'के', 'बाद', 'मुँह', 'साफ', 'करें', '।']\n",
            "Translated Sentence: ('सेठों', 'मुँह', 'पोटैटो', 'रौहें', 'बाद')\n",
            "Translation BLEU Scores [0.04282963710525157, 0.20252884954471367, 0.08515289178380434, 0.15846701826473467, 0.07740189180437576, 0.20327794960528028]\n",
            "Sentence Index:  10\n",
            "English Sentence: ['Not', 'only', 'teeth', 'starts', 'shining', 'with', 'this', '.']\n",
            "Reference Hindi Sentence: ['इससे', 'न', 'केवल', 'दाँत', 'चमचमाने', 'लगते', 'हैं', '।']\n",
            "Translated Sentence: ('शाइनी', 'केवल', 'दाँतों', 'विद', 'लगता', 'इस', 'रौहें')\n",
            "Translation BLEU Scores [0.028634401465295497, 0.16102307266026747, 0.05693025330278466, 0.17262789017258598, 0.07149888411075785, 0.24332831048358217]\n",
            "Sentence Index:  11\n",
            "English Sentence: ['If', 'there', 'is', 'health', 'there', 'is', 'everything', '.']\n",
            "Reference Hindi Sentence: ['सेहत', 'है', 'तो', 'सब', 'है', '।']\n",
            "Translated Sentence: ('जसाना', 'वहाँ', 'स्वास्थ्य', 'जसाना', 'सबकुछ', 'रौहें', 'वहाँ')\n",
            "Translation BLEU Scores [0, 0, 0, 0, 0, 0]\n",
            "Sentence Index:  12\n",
            "English Sentence: ['Eat', 'less', 'fatty', 'food', '.']\n",
            "Reference Hindi Sentence: ['कम', 'वसायुक्त', 'आहार', 'का', 'करें', 'सेवन', '।']\n",
            "Translated Sentence: ('फैटी', 'रौहें', 'कम', 'फूड')\n",
            "Translation BLEU Scores [0.037951271263104894, 0.1697232447536737, 0.07545383788761363, 0.09241478327137823, 0.04545349273020006, 0.12520207120947965]\n",
            "Sentence Index:  13\n",
            "English Sentence: ['Take', 'less', 'salt', 'and', 'alcohol', '.']\n",
            "Reference Hindi Sentence: ['नमक', 'और', 'शराब', 'का', 'सेवन', 'कम', 'करें', '।']\n",
            "Translated Sentence: ('रौहें', 'नमक', 'एवं', 'कम', 'शराब')\n",
            "Translation BLEU Scores [0.03880684294761699, 0.1781815298791261, 0.0771548656802496, 0.14358292775314402, 0.07745382231480302, 0.18327782179730542]\n",
            "Sentence Index:  14\n",
            "English Sentence: ['Stop', 'smoking', '.']\n",
            "Reference Hindi Sentence: ['बंद', 'करें', 'धूम्रपान', '।']\n",
            "Translated Sentence: ('रौहें', 'धूम्रपान')\n",
            "Translation BLEU Scores [0.05501080739920602, 0.19765609300943976, 0.10937121222607606, 0.05867012709475033, 0.047198954308813615, 0.08917419648057194]\n",
            "Sentence Index:  15\n",
            "English Sentence: ['Try', 'your', 'best', 'to', 'quit', 'it', '.']\n",
            "Reference Hindi Sentence: ['इसे', 'छोड़ने', 'की', 'पूरी', 'कोशिश', 'करें', '।']\n",
            "Translated Sentence: ('बुत', 'सर्वोत्तम', 'छोड़ो', 'आपकी', 'इसे', 'रौहें')\n",
            "Translation BLEU Scores [0.03455747170954952, 0.1869843520537038, 0.06870636427700044, 0.1688992412286964, 0.07240243729328812, 0.2340196377403126]\n",
            "Sentence Index:  16\n",
            "English Sentence: ['Exercise', 'daily', '.']\n",
            "Reference Hindi Sentence: ['रोज', 'करें', 'व्यायाम', '।']\n",
            "Translated Sentence: ('रौहें', 'दैनिक')\n",
            "Translation BLEU Scores [0, 0, 0, 0, 0, 0]\n",
            "Sentence Index:  17\n",
            "English Sentence: ['Keep', 'doing', 'light', 'physical', 'activities', '.']\n",
            "Reference Hindi Sentence: ['करते', 'रहें', 'हल्की', '-', 'फुल्की', 'शारीरिक', 'गतिविधियाँ', '।']\n",
            "Translated Sentence: ('हील', 'प्रकाश', 'गतिविधियों', 'शारीरिक', 'रौहें')\n",
            "Translation BLEU Scores [0.029486824119076216, 0.14983220973977976, 0.05862502026550899, 0.10909943235717327, 0.04928879601851102, 0.14894286548873903]\n",
            "Sentence Index:  18\n",
            "English Sentence: ['These', 'retain', 'the', 'flexibility', 'in', 'the', 'body', '.']\n",
            "Reference Hindi Sentence: ['इनसे', 'शरीर', 'में', 'लचीलापन', 'बना', 'रहता', 'है', '।']\n",
            "Translated Sentence: ('एकाग्रचित', 'सेठों', 'लचीलापन', 'मे', 'सेठों', 'रौहें', 'शरीर')\n",
            "Translation BLEU Scores [0.034052233956373766, 0.17820132316770917, 0.06770186228657868, 0.20529031524114758, 0.08738752502425957, 0.2638193908491072]\n",
            "Sentence Index:  19\n",
            "English Sentence: ['Summer', 'season', 'has', 'started', '.']\n",
            "Reference Hindi Sentence: ['गर्मी', 'का', 'मौसम', 'शुरू', 'हो', 'चुका', 'है', '।']\n",
            "Translated Sentence: ('ॠतु', 'चुका', 'शुभारम्भ', 'रौहें')\n",
            "Translation BLEU Scores [0.029556479778261396, 0.13218059591958078, 0.05876350803261634, 0.07197270557912354, 0.035399215731610215, 0.09750747110010456]\n",
            "Sentence Index:  20\n",
            "English Sentence: ['I', 'suffer', 'from', 'fever', 'continuously', '.']\n",
            "Reference Hindi Sentence: ['लगातार', 'बुखार', 'से', 'पीड़ित', 'हो', '?']\n",
            "Translated Sentence: ('डिस्पोजेबल', 'ज्वर', 'रौहें', 'लगातार', 'उद्\\u200dगमित')\n",
            "Translation BLEU Scores [0.0439891724758422, 0.22352339099197038, 0.08745825313180632, 0.16275722768907425, 0.07353024321741747, 0.22219664527356253]\n",
            "Sentence Index:  21\n",
            "English Sentence: ['What', 'are', 'the', 'primary', 'symptoms', 'of', 'kalajar', '.']\n",
            "Reference Hindi Sentence: ['कालाजार', 'के', 'प्रारंभिक', 'लक्षण', 'क्या', 'हैं', '?RD_PUNC']\n",
            "Translated Sentence: ('सेठों', 'सार्बिटॉल', 'लक्षणों', 'रौहें', 'प्राथमिक', 'ऑफ')\n",
            "Translation BLEU Scores [0, 0, 0, 0, 0, 0]\n",
            "Sentence Index:  22\n",
            "English Sentence: ['I', 'have', 'light', 'fever', 'for', 'some', 'days', '.']\n",
            "Reference Hindi Sentence: ['कुछ', 'दिनों', 'से', 'हल्का', 'फीवर', 'रहता', 'है', '।']\n",
            "Translated Sentence: ('चुके', 'प्रकाश', 'ज्वर', 'दिनों', 'लिये', 'रौहें', 'कुछ')\n",
            "Translation BLEU Scores [0.034052233956373766, 0.17820132316770917, 0.06770186228657868, 0.20529031524114758, 0.08738752502425957, 0.2638193908491072]\n",
            "Sentence Index:  23\n",
            "English Sentence: ['X-ray', 'and', 'TC-DC', 'are', 'normal', '.']\n",
            "Reference Hindi Sentence: ['एक्सरे', ',', 'टीसी-डीसी', 'नार्मल', 'है', '।']\n",
            "Translated Sentence: ('रौहें', 'सार्बिटॉल', 'नॉर्मल', 'एवं')\n",
            "Translation BLEU Scores [0, 0, 0, 0, 0, 0]\n",
            "Sentence Index:  24\n",
            "English Sentence: ['Measure', 'the', 'fever', 'every', 'four', 'hours', '.']\n",
            "Reference Hindi Sentence: ['चार', '-', 'चार', 'घंटे', 'पर', 'फीवर', 'को', 'मापें', '।']\n",
            "Translated Sentence: ('सेठों', 'ज्वर', 'हर', 'रौहें', 'घंटों', 'चार')\n",
            "Translation BLEU Scores [0.024761510494160165, 0.1339801428338312, 0.049230261240159306, 0.12102159467251643, 0.05187861328249633, 0.1676823977300696]\n",
            "Sentence Index:  25\n",
            "English Sentence: ['What', 'is', 'H', '.', '.', '.']\n",
            "Reference Hindi Sentence: ['एच.आई.वी.', 'क्या', 'है', '?']\n",
            "Translated Sentence: ('रौहें', 'रौहें', 'रौहें', 'जसाना')\n",
            "Translation BLEU Scores [0, 0, 0, 0, 0, 0]\n",
            "Sentence Index:  26\n",
            "English Sentence: ['How', 'does', 'it', 'happens', '.']\n",
            "Reference Hindi Sentence: ['यह', 'कैसे', 'होता', 'है', '?RD_PUNC']\n",
            "Translated Sentence: ('परियॉडॉन्टिस्ट', 'इसे', 'धागेनुमा', 'रौहें')\n",
            "Translation BLEU Scores [0, 0, 0, 0, 0, 0]\n",
            "Sentence Index:  27\n",
            "English Sentence: ['State', 'the', 'solutions', 'of', 'prevention', '.']\n",
            "Reference Hindi Sentence: ['बचाव', 'के', 'उपाय', 'बताएँ', '?']\n",
            "Translated Sentence: ('सेठों', 'रोग-निदान', 'ऑफ', 'रौहें', 'रोकथाम')\n",
            "Translation BLEU Scores [0, 0, 0, 0, 0, 0]\n",
            "Sentence Index:  28\n",
            "English Sentence: ['This', 'is', 'a', 'kind', 'of', 'virus', '.']\n",
            "Reference Hindi Sentence: ['यह', 'एक', 'प्रकार', 'का', 'वायरस', 'होता', 'है', '।']\n",
            "Translated Sentence: ('एस्टिग्मेटिज्म', 'जसाना', 'ए', 'ऑफ', 'वायरस', 'रौहें')\n",
            "Translation BLEU Scores [0.02925226826055808, 0.15827883685397307, 0.05815868174415821, 0.14297012104798287, 0.06128734000630705, 0.19809334661269648]\n",
            "Sentence Index:  29\n",
            "English Sentence: ['Bones', 'become', 'weak', 'and', 'starts', 'melting', '.']\n",
            "Reference Hindi Sentence: ['इससे', 'हड्डियाँ', 'कमजोर', 'हो', 'जाती', 'हैं', 'और', 'गलने', 'लगती', 'हैं', '।']\n",
            "Translated Sentence: ('बनते', 'लगता', 'एवं', 'पिघलती', 'कमजोर', 'रौहें')\n",
            "Translation BLEU Scores [0.01774239756616722, 0.09600096733558856, 0.03527502360630137, 0.08671576183842811, 0.037172650766057885, 0.12014968820568216]\n",
            "Sentence Index:  30\n",
            "English Sentence: ['Paralysis', 'may', 'also', 'attack', 'in', 'this', 'situation', '.']\n",
            "Reference Hindi Sentence: ['इस', 'परिस्थिति', 'में', 'लकवा', 'भी', 'मार', 'सकता', 'है', '।']\n",
            "Translated Sentence: ('भी', 'अटैक', 'मई', 'मे', 'परिस्थिति', 'इस', 'रौहें')\n",
            "Translation BLEU Scores [0.03266828640925502, 0.165998261506368, 0.06495032985064743, 0.19694692641710707, 0.08952782582237775, 0.24587846481804737]\n",
            "Sentence Index:  31\n",
            "English Sentence: ['What', 'is', 'the', 'home', 'treatment', 'of', 'diarrhoea', '.']\n",
            "Reference Hindi Sentence: ['डायरिया', 'का', 'घरेलू', 'उपचार', 'क्या', 'है', '?']\n",
            "Translated Sentence: ('जसाना', 'सेठों', 'होम', 'डायरिया', 'उपचार', 'ऑफ', 'रौहें')\n",
            "Translation BLEU Scores [0.039281465090051315, 0.20556680845025987, 0.07809849842300641, 0.23681572145316945, 0.10080718985850609, 0.3043328142580808]\n",
            "Sentence Index:  32\n",
            "English Sentence: ['Does', 'kalajar', 'occur', 'because', 'of', 'sun', '.']\n",
            "Reference Hindi Sentence: ['धूप', 'के', 'कारण', 'क्या', 'कालाजार', 'रोग', 'होता', 'है', '?']\n",
            "Translated Sentence: ('मौतें', 'क्योंकि', 'ऑफ', 'धूप', 'रौहें')\n",
            "Translation BLEU Scores [0.02414176971688927, 0.12267223791558803, 0.04799810699119213, 0.0893230604141688, 0.04035425308254256, 0.12194410442718785]\n",
            "Sentence Index:  33\n",
            "English Sentence: ['Does', 'its', 'influence', 'increase', 'in', 'summer', '.']\n",
            "Reference Hindi Sentence: ['क्या', 'गर्मी', 'में', 'इसका', 'प्रकोप', 'बढ़', 'जाता', 'है', '?']\n",
            "Translated Sentence: ('मराठे', 'इसकी', 'बढ़ाएँ', 'मे', 'ग्रीष्म', 'रौहें')\n",
            "Translation BLEU Scores [0, 0, 0, 0, 0, 0]\n",
            "Sentence Index:  34\n",
            "English Sentence: ['Administer', 'the', 'DPT', 'vaccine', 'to', 'the', 'child', '.']\n",
            "Reference Hindi Sentence: ['बच्चे', 'को', 'डीपीटी', 'का', 'टीका', 'लगायें', '।']\n",
            "Translated Sentence: ('सेठों', 'वैक्सीन', 'बुत', 'रौहें', 'बच्चा', 'सेठों')\n",
            "Translation BLEU Scores [0, 0, 0, 0, 0, 0]\n",
            "Sentence Index:  35\n",
            "English Sentence: ['Get', 'eyes', 'checked', 'up', 'every', 'six', 'months', '.']\n",
            "Reference Hindi Sentence: ['हर', 'छह', 'माह', 'में', 'करें', 'आँखों', 'की', 'जाँच', '।']\n",
            "Translated Sentence: ('चेक', 'आँखों', 'उठ', 'हर', 'महीनों', 'छह', 'रौहें')\n",
            "Translation BLEU Scores [0.03266828640925502, 0.165998261506368, 0.06495032985064743, 0.19694692641710707, 0.08952782582237775, 0.24587846481804737]\n",
            "Sentence Index:  36\n",
            "English Sentence: ['Maintain', 'the', 'glass', 'or', 'contact', 'lens', '.']\n",
            "Reference Hindi Sentence: ['चश्मे', 'या', 'कांटैक्ट', 'लेंस', 'का', 'रखरखाव', 'करें', '।']\n",
            "Translated Sentence: ('सेठों', 'काँच', 'कॉन्टेक्\\u200dट', 'या', 'लेंस', 'रौहें')\n",
            "Translation BLEU Scores [0.03478700554542394, 0.1751643270174889, 0.06916271812933181, 0.1700210851830615, 0.0766091750078838, 0.21752950302192342]\n",
            "Sentence Index:  37\n",
            "English Sentence: ['Washing', 'eyes', 'regularly', '.']\n",
            "Reference Hindi Sentence: ['नियमित', 'आँखें', 'धोना', '।']\n",
            "Translated Sentence: ('कैप्सूल्स', 'आँखों', 'रौहें')\n",
            "Translation BLEU Scores [0, 0, 0, 0, 0, 0]\n",
            "Sentence Index:  38\n",
            "English Sentence: ['Everything', 'is', 'visible', 'so', 'clearly', '.']\n",
            "Reference Hindi Sentence: ['सब', 'कुछ', 'कितना', 'साफ', 'दिखता', 'है', '।']\n",
            "Translated Sentence: ('जसाना', 'दृष्टिगोचर', 'इतनी', 'साफ-साफ', 'रौहें')\n",
            "Translation BLEU Scores [0, 0, 0, 0, 0, 0]\n",
            "Sentence Index:  39\n",
            "English Sentence: ['Coral', 'reef', 'is', 'the', 'life', 'here', '.']\n",
            "Reference Hindi Sentence: ['कोरल', 'रीफ', '(', 'मूँगा', 'चट्\\u200dटानें', ')', 'यहाँ', 'का', 'जीवन', 'हैं', '।']\n",
            "Translated Sentence: ('शैलमाला', 'जसाना', 'सेठों', 'रौहें', 'यहाँ', 'जीवन')\n",
            "Translation BLEU Scores [0.021099385422893017, 0.106242534824037, 0.04194930905450254, 0.10312300096114015, 0.04646581345757236, 0.1319383129748485]\n",
            "Sentence Index:  40\n",
            "English Sentence: ['Every', 'thing', 'about', 'Maldive', 'was', 'overwhelming', '.']\n",
            "Reference Hindi Sentence: ['मालदीव', 'के', 'बारे', 'में', 'हर', 'बात', 'अभिभूत', 'करने', 'वाली', 'थी', '।']\n",
            "Translated Sentence: ('चीज', 'बारे', 'सिलसिला……', 'रौहें', 'था')\n",
            "Translation BLEU Scores [0.016182712188007015, 0.08222966016687185, 0.03217409328795944, 0.05987503796886982, 0.027050264784023764, 0.08174157769340736]\n",
            "Sentence Index:  41\n",
            "English Sentence: ['This', 'room', 'was', 'actually', 'a', 'dining', 'room', '.']\n",
            "Reference Hindi Sentence: ['वह', 'कमरा', 'दरअसल', 'एक', 'डाइनिंग', 'रूम', 'था', '।']\n",
            "Translated Sentence: ('यूटिलिटी', 'रूम', 'रूम', 'रौहें', 'था', 'दरअसल', 'ए')\n",
            "Translation BLEU Scores [0.037684991644924185, 0.19148978368719022, 0.07492442692259767, 0.22719108016695733, 0.10327616593776132, 0.2836367900126478]\n",
            "Sentence Index:  42\n",
            "English Sentence: ['But', 'knew', 'it', 'was', 'not', 'possible', '.']\n",
            "Reference Hindi Sentence: ['लेकिन', 'जानते', 'थे', ',', 'यह', 'मुमकिन', 'नहीं', 'था', '।']\n",
            "Translated Sentence: ('रौहें', 'इसे', 'था', 'इजीप्शियन', 'नही', 'संभव')\n",
            "Translation BLEU Scores [0.024761510494160165, 0.1339801428338312, 0.049230261240159306, 0.12102159467251643, 0.05187861328249633, 0.1676823977300696]\n",
            "Sentence Index:  43\n",
            "English Sentence: ['Anyway', 'we', 'reached', 'Ramnagar', 'at', '12', '.']\n",
            "Reference Hindi Sentence: ['खैर', 'हम', '12', 'बजे', 'रामनगर', 'पहुँच', 'गए', '।']\n",
            "Translated Sentence: ('पहुँची', 'हम', 'चौराहे', '12', 'रौहें')\n",
            "Translation BLEU Scores [0.035065941041239286, 0.1658165975077607, 0.06971729121692201, 0.1297418212019085, 0.06337130916665702, 0.16642990876447916]\n",
            "Sentence Index:  44\n",
            "English Sentence: ['While', 'returning', 'it', 'became', 'late', 'evening', '.']\n",
            "Reference Hindi Sentence: ['लौटते', 'देर', 'शाम', 'हो', 'गई', '।']\n",
            "Translated Sentence: ('स्वर्गीय', 'इसे', 'लौटते', 'शाम', 'बन्धनों', 'रौहें')\n",
            "Translation BLEU Scores [0.048549177170732344, 0.24446151121745052, 0.09652434877402241, 0.23728353900810106, 0.10691671651659736, 0.3035868772401984]\n",
            "Sentence Index:  45\n",
            "English Sentence: ['We', 'set', 'out', 'for', 'forest', 'inside', '.']\n",
            "Reference Hindi Sentence: ['हम', 'अंदर', 'जंगल', 'के', 'लिए', 'रवाना', 'हो', 'गए', '।']\n",
            "Translated Sentence: ('निकल', 'फोरेस्ट', 'सेट', 'भीतर', 'लिये', 'रौहें')\n",
            "Translation BLEU Scores [0, 0, 0, 0, 0, 0]\n",
            "Sentence Index:  46\n",
            "English Sentence: ['I', 'photographed', 'profusely', '.']\n",
            "Reference Hindi Sentence: ['मैंने', 'जमकर', 'फोटोग्राफी', 'की', '।']\n",
            "Translated Sentence: ('रामानन', 'घमौरियों', 'रौहें')\n",
            "Translation BLEU Scores [0, 0, 0, 0, 0, 0]\n",
            "Sentence Index:  47\n",
            "English Sentence: ['I', 'called', 'him', 'just', 'like', 'that', 'only', '.']\n",
            "Reference Hindi Sentence: ['मैंने', 'उसे', 'ऐसे', 'ही', 'फोन', 'लगा', 'दिया', '।']\n",
            "Translated Sentence: ('कहलाते', 'जैसी', 'अभी-अभी', 'कि', 'जबरदस्ती', 'केवल', 'रौहें')\n",
            "Translation BLEU Scores [0, 0, 0, 0, 0, 0]\n",
            "Sentence Index:  48\n",
            "English Sentence: ['He', 'asked', 'you', 'saw', 'tiger', 'or', 'not', '.']\n",
            "Reference Hindi Sentence: ['उसने', 'पूछा', 'टाइगर', 'देखा', 'या', 'नहीं', '।']\n",
            "Translated Sentence: ('पूछा', 'तुम', 'चाथम', 'टाइगर', 'नही', 'या', 'रौहें')\n",
            "Translation BLEU Scores [0.043472087194499145, 0.22089591134157885, 0.08643019616048525, 0.2620796772330101, 0.11913576983277992, 0.32719347222300477]\n",
            "Sentence Index:  49\n",
            "English Sentence: ['These', 'words', 'pricked', 'like', 'an', 'arrow', '.']\n",
            "Reference Hindi Sentence: ['उसके', 'यह', 'शब्द', 'तीर', 'की', 'तरह', 'चुभ', 'गए', '।']\n",
            "Translated Sentence: ('2881', 'रौहें', 'जैसी', 'शब्दों', 'तीर')\n",
            "Translation BLEU Scores [0.02414176971688927, 0.12267223791558803, 0.04799810699119213, 0.0893230604141688, 0.04035425308254256, 0.12194410442718785]\n",
            "Sentence Index:  50\n",
            "English Sentence: ['I', 'slowly', 'said', 'no', '.']\n",
            "Reference Hindi Sentence: ['मैंने', 'धीरे', 'से', 'कहा', ',', 'नहीं', '।']\n",
            "Translated Sentence: ('पस्त', 'धीरे-धीरे', 'कहा', 'रौहें')\n",
            "Translation BLEU Scores [0.037951271263104894, 0.1697232447536737, 0.07545383788761363, 0.09241478327137823, 0.04545349273020006, 0.12520207120947965]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcR-JpzNT8gp",
        "colab_type": "code",
        "outputId": "fc159f68-96da-4548-fb4e-e4aa00a4547a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "# Results:\n",
        "import statistics\n",
        "print(\"Number of Samples Tested Upon: \" + str(tested))\n",
        "print()\n",
        "\n",
        "print(\"Average BLEU Score using Various Smoothing Functions (considering all test samples)\")\n",
        "for key in total_BLEU:\n",
        "    print(\"Method \" + str(key) + \": \" + str(total_BLEU[key] / tested))\n",
        "print()\n",
        "print(\"Average BLEU Score using Various Smoothing Functions (considering test samples with at-least one word overlap)\")\n",
        "for key in total_BLEU:\n",
        "    print(\"Method \" + str(key) + \": \" + str(total_BLEU[key] / (tested - null_BLEU_count)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Samples Tested Upon: 50\n",
            "\n",
            "Average BLEU Score using Various Smoothing Functions (considering all test samples)\n",
            "Method 1: 0.023962386067538474\n",
            "Method 2: 0.11772246144817412\n",
            "Method 3: 0.047641460577321854\n",
            "Method 4: 0.1007182980620664\n",
            "Method 5: 0.04599983188143955\n",
            "Method 7: 0.1328434537268092\n",
            "\n",
            "Average BLEU Score using Various Smoothing Functions (considering test samples with at-least one word overlap)\n",
            "Method 1: 0.03423198009648354\n",
            "Method 2: 0.16817494492596302\n",
            "Method 3: 0.06805922939617408\n",
            "Method 4: 0.14388328294580915\n",
            "Method 5: 0.06571404554491365\n",
            "Method 7: 0.18977636246687027\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuXHPvjPeKyd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ^_^ Thank You"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}